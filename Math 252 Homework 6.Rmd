---
title: "Math 252 Homework 6"
author: "Matthew Schroeder"
date: "October 16, 2018"
output: html_document
---
<style type="text/css">
    ol { list-style-type: upper-alpha; }
</style>


### Chapter 8  

### 8.35  
  
Suppose that the random variable Y has a gamma distribution with parameters $\alpha = 2$ and an unknown $\beta$. In Exercise 6.40 you used the method of moment generating functions to prove a general result implying that $2Y/\beta$ has  $\chi^2$ distribution with four degrees of freedom.  Using $2Y/\beta$ as a pivotal quantity, derive a 90% confidence interval for $\beta$.  

$\textbf{Solution:}$  

As usual I will split the 10% outside the confidence interval to be half above and half below.  So I need to find a and b such that $P(2Y/\beta < a) = 0.05$ and $P(2Y/\beta > b ) = 0.05$

using R
````{r}
a = qchisq(0.05, 4)
b = qchisq(0.05, 4, lower.tail = FALSE)
print(c(a,b))
````

this gives   

$P(0.710723 \leq 2Y/\beta \leq 9.487729) = 0.95$ 

rearranging   

$P(\frac{2Y}{9.487729} \leq \beta \leq \frac{2Y}{0.710723}) = 0.95$   


So $(\frac{2Y}{9.487729}, \frac{2Y}{0.710723})$ gives a 90% confidence interval for $\beta$  

--  

### 8.37  

Suppose Y is normally distributed with mean 0 and unknown variance $\sigma^2$. Then $Y^2/\sigma^2$ has a $\chi^2$ distribution with 1 degree of freedom.  Use the pivotal quantity $Y^2/\sigma^2$ to find:  

#### a) A 95% confidence interval for $\sigma^2$  

$\textbf{Solution:}$  

Need a and b such that $P(a \leq Y^2/\sigma^2 \leq b) = 0.95$, so will choose a and b to satisfy  $P(Y^2/\sigma^2 < a) = 0 0.025$ and  $P(Y^2/\sigma^2 > b) = 0 0.025$.  

````{r}

a = qchisq(0.025, 1)
b = qchisq(0.025, 1, lower.tail = FALSE)
print(c(a,b))

````

So $P(0.00098207 \leq Y^2/\sigma^2 \leq 5.02388619) = 0.95$

rearranging $P(\frac{Y^2}{5.02388619} \leq \sigma^2 \leq \frac{Y^2}{0.00098207}) = 0.95$

So $(\frac{Y^2}{5.02388619}, \frac{Y^2}{0.00098207})$ is a 95% confidence interval for $\sigma^2$  

--

#### b) A 95% upper confidence limit for $\sigma^2$  

$\textbf{Solution:}$   

Want $P(b \leq Y^2/\sigma^2) = 0.95$  

````{r}

b = qchisq(0.05, 1)
print(b)

````

So $P(0.00393214 \leq Y^2/\sigma^2) = 0.95$ 

$P(\sigma^2 \leq \frac{Y^2}{0.00393214}) = 0.95$ 

$\frac{Y^2}{0.00393214}$ is a 95% upper confidence limit for $\sigma^2$  

--

#### c) A 95% lower confidence limit for $\sigma^2$  

$\textbf{Solution:}$  

Want $P(Y^2/\sigma^2 \leq a) = 0.95$  

````{r}

a = qchisq(0.95, 1)
print(a)

````

So $P(Y^2/\sigma^2 \leq 3.841459) = 0.95$ 

$P(\frac{Y^2}{3.841459} \leq \sigma^2) = 0.95$ 

$\frac{Y^2}{3.841459}$ is a 95% lower confidence limit for $\sigma^2$   

--

### 8.74  

The Environmental Protection Agency has collected data on LC50 measurements (concentrations that kill 50% of test animals) for certain chemicals likely to be found in freshwater rivers and lakes. (See Exercise 7.5 for additional details.)  For certain species of fish, the LC50 measurements (in parts per million) for DDT in 12 experiments were as follows 16,5,21,19,10,5,8,2,7,2,4,9.  Estimate the true mean LC50 for DDT, with confidence coefficient 0.90. Assume that the LC50 measurements have an approximately normal distribution.  

$\textbf{Solution:}$   

Given that the measurements are approximately normal, I can use the formula $\overline{Y} \pm t_{\frac{\alpha}{2}}\left( \frac{S}{\sqrt{n}}\right)$, where $t_{\frac{\alpha}{2}}$ is determined for n-1 degrees of freedom.  

the following values need to be calculated $\overline{Y}$, S, and $t_{\frac{\alpha}{2}}$, where $\alpha = 0.05$  

````{r}

n = 12
data = c(16,5,21,19,10,5,8,2,7,2,4,9)
Ybar = mean(data)
S = sd(data)
ts = qt(0.05, n-1, lower.tail = FALSE)

print(c(Ybar - ts*(S/sqrt(n)), Ybar + ts*(S/sqrt(n))))
````

The 90% confidence interval for the true mean estimate is (5.669423, 12.330577)  

--  

### 8.76

Do SAT scores for high school students differ depending on the students' intended field of study?  15 students who intended to study engineering were compared with 15 students who inteded to major in language and literature.  Given in the accompanying table are the means and standard deviations of the scores on the verbal and mathematics portion of the SAT for the two groups of students.  
$\quad\quad\quad\quad\quad\quad\quad\quad$ Math $\quad\quad\quad\quad\quad\quad$Verbal  
Engineering $\;\overline{Y} = 446 \quad S = 42 \quad \overline{Y}= 548 \quad S= 57$  
Literature  $\quad\overline{Y} = 534 \quad S = 45 \quad \overline{Y}= 517 \quad S= 52$  

For the rest of this problem I will use the notation  

$\mu_{EV}, \overline{Y}_{EV}, S_{EV}$ = true mean, sample mean, sample standard deviation of engineering students on verbal  
  
$\mu_{EM}, \overline{Y}_{EM}, S_{EM}$ = true mean, sample mean, sample standard deviation  of engineering students on math   
  
$\mu_{LV}, \overline{Y}_{LV}, S_{LV}$ = true mean, sample mean, sample standard deviation  of literature students on verbal  
  
$\mu_{LM}, \overline{Y}_{LM}, S_{LM}$ = true mean, sample mean, sample standard deviation  of literature students on math   
  

#### a) Construct a 95% confidence interval for the difference in the average verbal score of students majoring in engineering and of those majoring in language/literature  

$\textbf{Solution:}$  
    
I will assume the conditions for the formulas derived in section 8.8 are satisfied and use them.   The conditions I am assuming hold are specified in part d) below.


The formula for the 95% confidence interval for $\mu_{EV} - \mu_{LV}$ is  

$\overline{Y}_{EV} - \overline{Y}_{LV} \pm t_{\frac{\alpha}{2}}S_p\sqrt{\frac{1}{n_1} + \frac{1}{n_2}}$  

where $\nu = n_1 + n_2 -2$ and $S_p^2 = \frac{(n_1 - 1)S_{EV}^2 + (n_2-1)S_{LV}^2}{n_1 + n_2 - 2}$

plugging everthing in 

````{r}
CIrange = 0.95
alpha = 1 - .95
n1 = 15
n2 = 15
nu = n1+n2-2
Yev = 446
Sev = 42
Ylv = 534
Slv = 45
Sp = sqrt(((n1-1)*Sev^2+(n2-1)*Slv^2)/nu)
ts = qt(alpha / 2, nu, lower.tail = FALSE)
lower = Yev - Ylv - ts*Sp*sqrt(2/15)
upper = Yev - Ylv + ts*Sp*sqrt(2/15)
print(c(lower,upper))
````

So a 95% confidence interval for $\mu_{EV} - \mu_{LV}$ is given by (-120.55614  -55.44386)  

-- 

#### b)  Construct a 95% confidence interval for the difference in the average math score of students majoring in engineering and of those majoring in language/literature  

$\textbf{Solution:}$   

This is exactly the same exercise with different numbers plugged in, so I will skip to the R code  

````{r}
CIrange = 0.95
alpha = 1 - .95
n1 = 15
n2 = 15
nu = n1+n2-2
Yem = 548
Sem = 57
Ylm = 517
Slm = 52
Sp = sqrt(((n1-1)*Sem^2+(n2-1)*Slm^2)/nu)
ts = qt(alpha / 2, nu, lower.tail = FALSE)
lower = Yem - Ylm - ts*Sp*sqrt(2/15)
upper = Yem - Ylm + ts*Sp*sqrt(2/15)
print(c(lower,upper)) 

````
    
So a 95% confidence interval for $\mu_{EM} - \mu_{LM}$ is given by (-9.807369, 71.807369)     

--

#### c)  Interpret the results obtained in a) and b)  

$\textbf{Solution:}$ 

Since both endpoints for the 95% confidence interval for $\mu_{EV} - \mu_{LV}$ are negative, one can conclude that there is most likely a difference in the true means of the verbal SAT scores for the two groups.
Since one endpoint is negative and one is positve for $\mu_{EM} - \mu_{LM}$ one can not conclude that there is a difference in true means for the math SAT. 

#### d) What assumptions are necessary for the methods used previously to be valid.  

$\textbf{Solution:}$  

One must assume that the samples are independent and the populations are normally distributed with equal standard deviations.  

--

### 8.79  

A factory operates two machines of type A and one machine of type B. The weekly repair costs X for type A machines are normally distributed with mean $\mu_1$ and variance $\sigma^2$ The weekly repair costs Y for machines of type B are normally distributed with mean $\mu_2$ and variance $3\sigma^2$. The expected repair cost per week for the factory is this $2\mu_1 + \mu_2$. If you are given a random sample $X_1,...,X_n$ on costs of type A machines and an independent random sample $Y_1,...,Y_m$ on costs for type B machines, show how you would construct a 95% confidence interval for $2\mu_1 + \mu_2$:  

#### a: If $\sigma^2$ is known.  

$\textbf{Solution:}$  

Since $X_1,...,X_n$ and $Y_1,...,Y_m$ are independent ramdom samples which are normallly distributed, $2\overline{X} + \overline{Y}$ is normally distributed with mean $2\mu_1 + \mu_2$ and variance $\frac{4\sigma^2}{n} + \frac{3\sigma^2}{m}$.  So we can form the standardized normal distribution and use the result as a pivotal value (since $\sigma^2$ is known).

$P(a \leq \frac{2\overline{X} + \overline{Y} - (2\mu_1 + \mu_2)}{\sqrt{\frac{4\sigma^2}{n} + \frac{3\sigma^2}{m}}} \leq b) = 0.95$  

Since this is standard normal, we can use the well known value for 95% of 1.96

$P(-1.96 \leq \frac{2\overline{X} + \overline{Y} - (2\mu_1 + \mu_2)}{\sqrt{\frac{4\sigma^2}{n} + \frac{3\sigma^2}{m}}} \leq 1.96) = 0.95$ 

rearranging 

$P(2\overline{X} + \overline{Y} - 1.96\sigma\sqrt{\frac{4}{n} + \frac{3}{m}} \leq 2\mu_1 + \mu_2 \leq 2\overline{X} + \overline{Y} + 1.96\sigma\sqrt{\frac{4}{n} + \frac{3}{m}}) = 0.95$   

So $\left(2\overline{X} + \overline{Y} - 1.96\sigma\sqrt{\frac{4}{n} + \frac{3}{m}}, 2\overline{X} + \overline{Y} + 1.96\sigma\sqrt{\frac{4}{n} + \frac{3}{m}} \right)$ is a 95% confidence interval for $ 2\mu_1 + \mu_2$ in the case that $\sigma^2$ is known.  

--  

#### b: If $\sigma^2$ is not known.  

$\textbf{Solution:}$   

I am going to write this out in detail to make sure I understand the steps  

In this case, just as in the case of the difference of means developed in the book, a estimator of the variance $\sigma^2$ must found, and this will be used to form a t-distributed random variable which can be used as a pivotal value.  

We will start with the standard normal random variable as used in part a)

$\frac{2\overline{X} + \overline{Y} - (2\mu_1 + \mu_2)}{\sigma\sqrt{\frac{4}{n} + \frac{3}{m}}}$  

The goal is to eliminate $\sigma$ and get a pivotal value whose distribution does not depend on $2\mu_1 + \mu_2$

If we divide a standard normal by $\sqrt{W/k}$, where W is a $\chi^2$ distributed random variable with k degrees of freedom, the result will be a t distributed random variable.  In this case we want to do this so the t distribution does not depend on $2\mu_1 + \mu_2$  and $\sigma$ cancels.
  
$\frac{n-1}{\sigma^2}S_X = \frac{1}{\sigma^2}\sum\limits_{i = 1}^{n}(X_i - \overline{X})^2$ and   $\frac{m-1}{3\sigma^2}S_Y = \frac{1}{3\sigma^2}\sum\limits_{i = 1}^{m}(Y_i - \overline{Y})^2$ are independent $\chi^2$ random variables with $n-1$ and $m-1$ degrees of freedom respectively. 
So    
$\frac{1}{\sigma^2}\sum\limits_{i = 1}^{n}(X_i - \overline{X})^2 + \frac{1}{3\sigma^2}\sum\limits_{i = 1}^{m}(Y_i - \overline{Y})^2$ is a $\chi^2$ distributed random variable with $n+m-2$ degrees of freedom  

rewriting this  

$\frac{n+m-2}{\sigma^2}\left(\left((n-1)\frac{1}{n-1}\sum\limits_{i = 1}^{n}(X_i - \overline{X})^2 + \frac{m-1}{3}\frac{1}{m-1}\sum\limits_{i = 1}^{m}(Y_i - \overline{Y})^2 \right)/(n+m-2) \right)  = \frac{n+m-2}{\sigma^2}\left(\left((n-1)S_X^2 + (\frac{m-1}{3})S_Y^2 \right)/(n+m-2)\right)$

So Will define  $S_p^2 = \frac{(n-1)S_X^2 + \frac{m-1}{3}S_Y^2}{n+m-2}$ and note that $\frac{(n+m-2)S_p^2}{\sigma^2}$ is $\chi^2$ with $n+m-2$ degrees of freedom

To summarize: 

We have a standard normal random variable $\frac{2\overline{X} + \overline{Y} - (2\mu_1 + \mu_2)}{\sigma\sqrt{\frac{4}{n} + \frac{3}{m}}}$  

We have a $\chi_{n+m-2}^2$ distributed random variable  $\frac{n+m-2}{\sigma^2}S_p^2$

So $\frac{2\overline{X} + \overline{Y} - (2\mu_1 + \mu_2)}{\sigma\sqrt{\frac{4}{n} + \frac{3}{m}}} \bigg{/} \left(\sqrt{\frac{(n+m-2)^2S_p^2}{\sigma^2} \bigg{/} (n+m-2)} \right) = \frac{2\overline{X} + \overline{Y} - (2\mu_1 + \mu_2)}{S_p\sqrt{\frac{4}{n} + \frac{3}{m}}}$ has a t distribution and this distribution does not depend on $2\mu_1 + \mu_2$ and will be used as the pivotal value

$P(-t_{0.025} \leq  \frac{2\overline{X} + \overline{Y} - (2\mu_1 + \mu_2)}{S_p\sqrt{\frac{4}{n} + \frac{3}{m}}} \leq t_{0.025}) = 0.95$  here I am using the notation of the book that $t_{0.025}$ is the quantile corresponding to the upper tail of the t distribution.

 

$\left(2\overline{X} + \overline{Y} - t_{0.025}S_p\sqrt{\frac{4}{n} + \frac{3}{m}},  2\overline{X} + \overline{Y} + t_{0.025}S_p\sqrt{\frac{4}{n} + \frac{3}{m}} \right)$ is a 95% confidence interval for $2\mu_1 + \mu_2$ when $\sigma^2$ is not known.  

--  

### 8.81  

Recently, the EPA set a maximum noise level for heavy trucks at 83 dB.  The manner in which this limit is applied will greatly affect the trucking industry and the public. One way to apply the limit is to require that all trucks conform to the limit.  A second, but less satisfactory, method is to require that the truck fleet's mean noise level be less than the limit.  If the latter is adopted, then variation in the noise level from truck to truck becomes important, because a large value of $\sigma^2$ would imply that many trucks exceed the limit, even if the mean fleet level were 83 dB.  A random sample of six heavy trucks produced the following noise levels in decibels,  

85.4, 86.8, 86.1, 85.3, 84.8, 86.0  

Use this data to construct a 90% confidence interval for $\sigma^2$, the variance of the truck noise emission readings.  Interpret your results.  

$\textbf{Solution:}$   

If we assume that these measurements are normally distributed then the 90% confidence interval is given by   

$\left(\frac{(n-1)S^2}{\chi_{0.05}^2}, \frac{(n-1)S^2}{\chi_{0.95}^2}\right)$  

To compute this I will use R

````{r}

data = c(85.4, 86.8, 86.1, 85.3, 84.8, 86.0)
n = 6
S = sd(data)
chiL = qchisq(0.05, n-1, lower.tail = TRUE)
chiU = qchisq(0.95, n-1, lower.tail = TRUE)

print(c((n-1)*S^2/chiU, (n-1)*S^2/chiL))

````
So the 90% confidence interval for $\sigma^2$ is given by (0.2270298, 2.1941384). So assuming normally distributed measurements, this tells us, with 90% confidence, that the true population variance, $\sigma^2$, will be in this interval.  

--

### 8.109

Suppose that independent sample of sizes $n_1$ and $n_2$ are taken from two normally distributed populations with variances $\sigma_1^2$ and $\sigma_2^2$, respectively.  If $S_1^2$ and $S_2^2$ demote the respective sample variances, Theorem 7.3 implies that $\frac{(n_1-1)S_1^2}{\sigma_1^2}$ and $\frac{(n_2-1)S_2^2}{\sigma_2^2}$ have $\chi^2$ distributions with $n_1-1$ and $n_2-1$ degrees of freedom respectively.  Furtherm these $\chi^2$-distributed ramdom variables are independent because the samples were independently taken.  

#### a) Use these quantities to construct a random variable that has an F distribution with $n_1-1$ numerator degrees of freedom and $n_2-1$ denominator degrees of freedom.   

$\textbf{Solution:}$   

Well, given Definition 7.3  

$\frac{\frac{(n_1-1)S_1^2}{\sigma_1^2}\bigg/(n_1-1)}{\frac{(n_2-1)S_2^2}{\sigma_2^2}\bigg/(n_2-1)} = \frac{S_1^2 / \sigma_1^2}{S_2^2 / \sigma_2^2} = \frac{S_1^2}{S_2^2}\frac{\sigma_2^2}{\sigma_1^2}$  


Is the desired random variable.  

#### b) Use the F-distributed quantity from a) as a pivotal quantity, and derive a formula for a $100(1-\alpha)$% confidence interval for $\frac{\sigma_2^2}{\sigma_1^2}$   

$\textbf{Solution:}$   

Using the notation of the book that $F_{\beta}$ is the number such that $P(F > F_{\beta}) = \beta$

$P\left(F_{\left(1 - \frac{\alpha}{2}\right)} \leq \frac{S_1^2}{S_2^2}\frac{\sigma_2^2}{\sigma_1^2} \leq F_{\frac{\alpha}{2}} \right) = 1-\alpha$  

rearranging  

$P\left(\frac{S_2^2}{S_1^2}F_{\left(1 - \frac{\alpha}{2}\right)} \leq \frac{\sigma_2^2}{\sigma_1^2} \leq \frac{S_2^2}{S_1^2}F_{\frac{\alpha}{2}} \right) = 1-\alpha$  

so the $100(1 - \alpha)$% confidence interval for $\frac{\sigma_2^2}{\sigma_1^2}$ is given by  

$\left(\frac{S_2^2}{S_1^2}F_{\left(1 - \frac{\alpha}{2}\right)},  \frac{S_2^2}{S_1^2}F_{ \frac{\alpha}{2}}\right)$  

Okay.  I looked at the answer at the back of the book and two things are different.  

- The answer there makes explicit the degree of freedom parameters for the F distribution in the notation to indicate the quantile, i.e. $F_{\nu_1,\nu_2, \frac{\alpha}{2}}$.  This is not how the book itself notated  these values on page 340 and 341 and I did not do so. 

- The answer uses a property of the F distribution which I did not use.  Namely $F_{\nu_1,\nu_2,(1-\beta)} = 1/F_{\nu_2,\nu_1,\beta}$, where the numerator and denominator degrees of freedom have switched.    

  This follows by noting that $\quad F_{\nu_1,\nu_2} = W_1/\nu_1\big{/}W_2/\nu_2 = \frac{1}{W_2/\nu_2\bigg{/}W_1/\nu_1} = 1/F_{\nu_2,\nu_1}$  Therefore
    
  $\beta = P(F_{\nu_2,\nu_1} > F_{\nu_2,\nu_1, \beta} ) = P(1 / F_{\nu_2,\nu_1} \leq 1/F_{\nu_2,\nu_1,\beta} ) = 1 - P(1 / F_{\nu_2,\nu_1} > 1/F_{\nu_2,\nu_1, \beta}) =  1 - P(F_{\nu_1,\nu_2} > 1/F_{\nu_2,\nu_1, \beta})$  
     
    
  $\Longrightarrow \quad  1-\beta = P(F_{\nu_1,\nu_2} > 1/F_{\nu_2,\nu_1, \beta})$ so by definition $F_{\nu_1,\nu_2, (1-\beta)} = 1/F_{\nu_2,\nu_1, \beta}$


so the $100(1 - \alpha)$% confidence interval for $\frac{\sigma_2^2}{\sigma_1^2}$ is given by  

$\left(\frac{S_2^2}{S_1^2}\frac{1}{F_{(n_2-1),(n_1-1),\frac{\alpha}{2}}},  \frac{S_2^2}{S_1^2}F_{(n_1-1),(n_2-1), \frac{\alpha}{2}}\right)$   

--

### 8.113  

Suppose that two independent random samples of $n_1$ and $n_2$ observations are selected from normal populations.  Further, assume that the populations possess a common variance $\sigma^2$.  Let  

$S_i^2 = \frac{\sum\limits_{j = 1}^{n_i}\left(Y_{ij} - \overline{Y_i} \right)}{n_i - 1}$ for $i = 1,2$  

#### a) Show that $S_p^2 = ((n_1-1)S_1^2 + (n_2-1)S_2^2)\big{/}(n_1+n_2-2)$, the pooled estimator of $\sigma^2$, is unbiased.  

$\textbf{Solution:}$  

If $E(S_p^2) = \sigma^2$ then it is an unbiased estimator

It was shown in Example 8.1 that $E(S_i^2) = \sigma^2$ so  

$E(S_p^2) = ((n_1-1)E(S_1^2) + (n_2-1)E(S_2^2))\big{/}(n_1+n_2-2) = \sigma^2 \frac{n_1+n_2-2}{n_1+n_2-2} = \sigma^2$  


#### b) Find $V(S_p^2)$  

$\textbf{Solution:}$   

Since the random samples are independent we have  

$V(S_p^2) = ((n_1-1)^2V(S_1^2) + (n_2-1)^2V(s_2^2))\big{/}(n_1+n_2-2)^2$  

I believe we already showed that $V(S_i^2) = \frac{2\sigma^4}{n_i-1}$ but I cannot find it so I will show it again  

$\frac{n_i-1}{\sigma^2}S_i^2$ is $\chi^2$ with $n_i-1$ degrees of freedom so $V(\frac{n_i-1}{\sigma^2}S_i^2) = 2(n_i-1)$   
  
also  $V(\frac{n_i-1}{\sigma^2}S_i^2) = \frac{(n_i-1)^2}{\sigma^4}V(S_i^2)$ so   

$\frac{(n_i-1)^2}{\sigma^4}V(S_i^2) = 2(n_i-1) \quad \Longrightarrow \quad V(S_i^2) = \frac{2\sigma^4}{n_i-1}$  

plugging in   

$V(S_p^2) = ((n_1-1)^2V(S_1^2) + (n_2-1)^2V(s_2^2))\big{/}(n_1+n_2-2)^2 = ((n_1-1)2\sigma^4 + (n_2-1)2\sigma^4)\big{/}(n_1+n_2-2)^2 = 2\sigma^4 \big{/}(n_1+n_2-2)$


--

