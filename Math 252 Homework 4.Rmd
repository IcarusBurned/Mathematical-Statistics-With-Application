---
title: "Math 252 Homework 4"
author: "Matthew Schroeder"
output:
  html_document: default
  pdf_document: default
---

<style type="text/css">
    ol { list-style-type: upper-alpha; }
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Chapter 6

### 6.59  

As in Exercise 5.58, let $Y_1$ and $Y_2$ be independent and uniformly distributed over the interval (0,1).  

a. Find the probability density function of $U_2 = max(Y_1,Y_2)$.  

    $\textbf{Solution:}$

    From the book, the formula for the probability density function of $Y_{(n)} = max(Y_1,Y_2)$ is given by:  
    
    $f_{U_2} = 2\left[F(u)\right]f(u)$ 
    
    Since $Y_1$ and $Y_2$ be independent and uniformly distributed over the interval (0,1) we have  
    
    $f(u) = \begin{cases}  1 & 0 < u < 1\\ 0 & \text{elsewhere} \end{cases}$  
    
    so   
    
    $F(u) = P(Y \leq u) = \begin{cases} \int\limits_{0}^{u}1dy & 0 < y < 1\\ 0 & \text{elsewhere} \end{cases} = \begin{cases} u & 0 < u < 1\\ 0 & \text{elsewhere} \end{cases}$  
    
    plugging in
    
    $f_{U_2}(u) = \begin{cases}  2u & 0 < u < 1 \\ 0 & \text{elsewhere} \end{cases}$   
    
    --

b. Find $E(U_2)$ and $V(U_2)$   

    $\textbf{Solution:}$  
    
    $E(U_2) = \int\limits_{-\infty}^{\infty}2uf_{U_2}(u)du = \int\limits_{0}^{1}2u^2du = \frac{2}{3}$  
    
    similarily  
    
    $E(U_2^2) = \int\limits_{0}^{1}2u^3du = \frac{1}{2}$ 
    
    so  
    
    $V(U_2) = E(U_2^2) - E(U_2)^2 = \frac{1}{2} - \frac{4}{9} = \frac{1}{18}$  
    
    
    --  
    
<P style="page-break-before: always">
### 6.65  

Let $Y_1,...,Y_n$ be independent, exponentially distributed random variables with mean $\beta$.  

a. Show that $Y_{(1)} = min(Y_1,...,Y_n)$ has an exponential distribution, with mean $\frac{\beta}{n}$.  

    $\textbf{Solution:}$  
    
    From the book, the formula for the probability density function of $Y_{(1)} = max(Y_1,...,Y_n)$ is given by:
    
    $f_{Y_{(1)}}(y) = n[1 - F(y)]^{n-1}f(y)$  
    
    Since $Y_1,...,Y_n$ are exponentially distributed with mean $\beta$ we have  
    
    $f(y) =  \begin{cases} \frac{1}{\beta}e^{-\frac{y}{\beta}} & 0 < y < \infty \\ 0 & \text{elsewhere} \end{cases}$   
    
    so  
    
    $F(y) = P(Y \leq y) = \begin{cases} \int\limits_{0}^{y}\frac{1}{\beta}e^{-\frac{x}{\beta}}dx & 0 < y < \infty \\ 0 & \text{elsewhere} \end{cases} = \begin{cases} 1-e^{-\frac{y}{\beta}} & 0 < y < \infty\\ 0 & \text{elsewhere} \end{cases}$   
    
    plugging in  
    
    $f_{Y_{(1)}}(y) = \begin{cases} n[e^{-\frac{y}{\beta}}]^{n-1}\frac{1}{\beta}e^{-\frac{y}{\beta}}& 0 < y < \infty\\ 0 & \text{elsewhere} \end{cases}= \begin{cases} \frac{n}{\beta}e^{-\frac{ny}{\beta}}& 0 < y < \infty\\ 0 & \text{elsewhere} \end{cases}$   
    
    The last is an exponential distribution, with mean $\frac{\beta}{n}$  
    
    --
    
b. If $n=5$ and $\beta = 2$, find $P(Y_{(1)} \leq 3.6)$.  

    $\textbf{Solution:}$  
    
    $P(Y_{(1)} \leq 3.6) = \int\limits_{0}^{3.6}\frac{5}{2}e^{-\frac{5}{2}x}dx = -e^{-\frac{5}{2}x} \big{|}_{0}^{3.6}= 1 - e^{-\frac{5}{2}3.6} = 1-e^{-9}$   
    
    --    
<P style="page-break-before: always">    
### Chapter 7  

### 7.1  

Refer to Example 7.1. The amount of fill dispensed by a bottling machine is normally distributed with $\sigma = 1$ ounce. if $n=9$ bottles are ramdomly selected from the output of the machine, we found that the probability that the sample mean will be within 0.3 ounce of the true mean is 0.6318.  Suppose that $\overline{Y}$ is to be computed using a sample size n.  

a. If $n=16$, what is $P(|\overline{Y} - \mu| \leq 0.3)$?  

    $\textbf{Solution:}$  
    
    From Example 7.1 we see that $P(|\overline{Y} - \mu| \leq 0.3) = P(-0.3\sqrt{n} \leq Z \leq 0.3\sqrt{n})$  
    
    A program to compute this probability and those for part b. is shown just below part b  
    
    $n = 16:\quad$  0.7698607  
    

b. Find $P(|\overline{Y} - \mu| \leq 0.3)$ when $\overline{Y}$ is to be computed using sample sizes $n=25,n=36,n=49, \text{ and } n=64$.  

    $\textbf{Solution:}$  
    
    n = 25: $\quad$  0.8663856  
    n = 36: $\quad$  0.9281394  
    n = 49: $\quad$  0.9642712   
    n = 64: $\quad$  0.9836049  
    

```{r}
normal_remove_tail_prob <- function(n, q)
{
  rslt = 1 - 2*pnorm(q*sqrt(n), lower.tail = FALSE)
  return(rslt)
}

n16 = normal_remove_tail_prob(16, 0.3)
n25 = normal_remove_tail_prob(25, 0.3)
n36 = normal_remove_tail_prob(36, 0.3)
n49 = normal_remove_tail_prob(49, 0.3)
n64 = normal_remove_tail_prob(64, 0.3)

print(c(n16,n25, n36, n49, n64))

```


c. What pattern do you observe among the values for $P(|\overline{Y} - \mu| \leq 0.3)$ that you observed for the various values of n?  

    $\textbf{Solution:}$  
    
    As the number of samples increases, the probability thatthe sample mean will be within 0.3 of the true mean increases.  
    
    
d. Do the results that you obtained in part b) seem to be consistent with the results obtained in Example 7.2?  

    $\textbf{Solution:}$   
    
    Yes, the results are consistent.  In Example 7.2, 43 samples are needed to get $P(|\overline{Y} - \mu| \leq 0.3) = 0.95$.  The sample number obtained for 0.95 is in between n = 36 for 0.93 and n = 49 for 0.96  
    

<P style="page-break-before: always">
### 7.7  

Suppose that $X_1,...,X_m \text{ and } Y_1,...,Y_n$ are independent random samples, with the variables $X_i$ normally distributed with mean $\mu_1$ and variance $\sigma_1^2$ and the variables $Y_i$ normally distributed with mean $\mu_2$ and variance $\sigma_2^2$.  The difference between the sample means, $\overline{X} - \overline{Y}$ is then a linear combination of $m+n$ normally distributed random variables and, by Theorem 6.3, is itself normally distributed.  

a. Find $E(\overline{X} - \overline{Y})$.  

    $\textbf{Solution:}$   
    
    From theorem 6.3, we have $E(\overline{X} - \overline{Y}) = E(\overline{X}) - E(\overline{Y}) = E\left(\frac{1}{m}\sum\limits_{i = 1}^m X_i \right) - E\left(\frac{1}{n}\sum\limits_{i = 1}^n Y_i \right) = \frac{1}{m}\sum\limits_{i = 1}^m E(X_i) - \frac{1}{n}\sum\limits_{i = 1}^n E(Y_i) = \mu_1 - \mu_2$  
    
    --
  
b. Find $V(\overline{X} - \overline{Y})$.  

    $\textbf{Solution:}$  
    
    By Theorem 7.3: $\sigma_{\overline{X}}^2 = \frac{\sigma_1^2}{m} \text{ and } \sigma_{\overline{Y}}^2 = \frac{\sigma_2^2}{n}$  
    
    So by Theorem 6.3 $V(\overline{X} - \overline{Y}) = \sigma_{\overline{X}}^2 + \sigma_{\overline{Y}}^2 = \frac{\sigma_1^2}{m} + \frac{\sigma_2^2}{n}$  
    
    --
  
c. Suppose that $\sigma_1^2 = 2$ and $\sigma_2^2 = 2.5$, and $m = n$. Find the sample sizes so the $(\overline{X} - \overline{Y})$ will be within one unit of $(\mu_1 - \mu_2)$ with probability 0.95    

    $\textbf{Solution:}$ 
 
    we are interested in $P(-1 \leq (\overline{X} - \overline{Y}) - (\mu_1 - \mu_2) \leq 1) = .95$.  
    
    To make this standard normal, divide by the standard deviation ${\sigma} = \frac{\sqrt(\sigma_1^2 + \sigma_2^2)}{\sqrt{n}} = \frac{\sqrt(4.5)}{\sqrt{n}}$.  
    
    This gives $P(-\frac{\sqrt{n}}{\sqrt(4.5)} \leq \frac{(\overline{X} - \overline{Y}) - (\mu_1 - \mu_2)}{\frac{\sqrt{n}}{\sqrt(4.5)}} \leq \frac{\sqrt{n}}{\sqrt(4.5)}) = .95$
    
    Since the bottom and upper tails need to be excluded to give 0.95, I divide the tail probability in half, 0.05 / 2 = 0.25, For this reason I will use .975 in R
    
    R is used to solve this 
    
```{r}


n = (qnorm(0.975) * sqrt(4.5))^2

n

```

    n = 18

--
<P style="page-break-before: always">
### 7.10  

a. If U has a $\chi^2$ distribution with $\nu$ degrees of freedom, find $E(U)$ and $V(U)$  

    $\textbf{Solution:}$   
    
    From the back of the book: $E(U) = \nu$ and $V(U) = 2\nu$.  
    
    --
    
b. Using the results of Theroem 7.3, find $E(S^2)$ and $V(S^2)$ when $Y_1,...,Y_n$ is a random sample from a normal distribution with mean $\mu$ and variance $\sigma^2$.  

    $\textbf{Solution:}$  
    
    By Theorem 7.3, $\frac{(n-1)S^2}{\sigma^2}$ has a $\chi^2$ distribution with n-1 degrees of freedom.  
    
    So $E(\frac{(n-1)S^2}{\sigma^2}) = n-1 \Rightarrow \frac{(n-1)}{\sigma^2}E(S^2) = n-1$  
    
    Therefore $\quad E(S^2) = \sigma^2$  
    
    $2(n-1) = V(\frac{(n-1)S^2}{\sigma^2}) = E(\left(\frac{(n-1)}{\sigma^2}\right)^2S^4) - E(\frac{(n-1)}{\sigma^2}S^2)^2 = \left(\frac{(n-1)}{\sigma^2}\right)^2(E(S^4) - E(S^2)^2 ) =\left(\frac{(n-1)}{\sigma^2}\right)^2V(S^2)$  
    
    Therefore $\quad V(S^2) = \frac{2\sigma^4}{n-1}$  
    
    ---
 <P style="page-break-before: always">   
### 7.14  

Suppose that $Z$ has a standard normal distribution and that Y is an independent $\chi^2$-distributed random variable with $\nu$ degrees of freedom. Then, according to Definition 7.2, $T=\frac{Z}{\sqrt{Y/\nu}}$ has a T distribution with $\nu$ degrees of freedom.  

a. If $Z$ has a standard normal distribution, give $E(Z)$ and $E(Z^2)$. [Hint: For any random variable, $E(Z^2) = V(Z) + E(Z)^2$]  

    $\textbf{Solution:}$  
    
    A standard normal distribution has 
    
    $E(Z) = 0$   
    
    $V(Z) = 1$  
    
    $E(Z^2) = V(Z) + E(Z)^2 = 1$  
    
    --  
    
b. According to the result derived in Exercise 4.90 (a),if $Y$ has a $\chi^2$ distribution with $\nu$ df, then  

    $(*) E(Y^a) = \frac{\Gamma\left(\frac{\nu}{2} + a \right)}{\Gamma\left( \frac{\nu}{2}\right)}2^a, \quad \quad \text{if } \nu > -2a$. 
    
    Use this result, the result from part (a), and the structure of T to show the following. [Hint: Recall the independence of Z and Y]

    - $E(T) = 0, \text{ if } \nu > 1$.  
    
        $\textbf{Solution:}$   
        
        $E(T) = E(\frac{Z}{\sqrt{Y/\nu}}) = E(Z\cdot \sqrt{\nu}Y^{-\frac{1}{2}}) = E(Z)E(\sqrt{\nu}Y^{-\frac{1}{2}}) = 0$  since $E(Z) = 0$.  
        
        I am not sure why $\nu >1$ has to be true for this result to hold.
    

    - $V(T) = \frac{\nu}{\nu - 2}, \text{ if } \nu > 2$  
    
        $\textbf{Solution:}$  
        
        The condition  $\nu > 2$ allows me to use $(*)$ when $a = -1$  
        
        $V(T) = E(T^2) - E(T)^2 = E(T^2) = \nu E(Z^2Y^{-1}) = \nu E(Z^2)E(Y^{-1}) = \nu E(Y^{-1}) = \nu \frac{\Gamma\left(\frac{\nu}{2} -1 \right)}{\Gamma\left( \frac{\nu}{2}\right)}2^{-1}$  
        
        Using the identity $\Gamma(\alpha) = (\alpha - 1)\Gamma(\alpha - 1)$  
        
        $V(T) = \nu \frac{\Gamma\left(\frac{\nu}{2} -1 \right)}{\Gamma\left( \frac{\nu}{2}\right)}2^{-1} = \frac{\nu}{\frac{\nu}{2} - 1}2^{-1} = \frac{\nu}{\nu -2}$  
        
        
        ---

<P style="page-break-before: always">
### 7.19  

Let $Y_1,...,Y_5$ be a random sample of size 5 from a normal population with mean 0 and variance 1, and let $\overline{Y} = \frac{1}{5}\sum\limits_{i = 1}^{5}Y_i$.  Let $Y_6$ be another independent observation from the same population.  

a. What is the distribution of $W = \sum\limits_{i = 1}^{5}Y_i^2$? Why?  

    $\textbf{Solution:}$   
    
    The Y_i are standard normal random variables, so by Theorem 7.2 $W = \sum\limits_{i = 1}^{5}Y_i^2$ has a $\chi^2$ distribution with 5 degrees of freedom.  
    
    
b. What is the distribution of $U = \sum\limits_{i = 1}^{5}(Y_i - \overline{Y})^2$? Why?  

    $\textbf{Solution:}$   
    
    By Theorem 7.3, with $\sigma^2$ = 1,  this is a $\chi^2$ distribution with 4 degrees of freedom.  
  
    
  
c. What is the distribution of $\sum\limits_{i = 1}^{5}(Y_i - \overline{Y})^2 + Y_6^2$? Why?  

    $\textbf{Solution:}$  
    
    Suppose $V_1$ is a random variable with $\chi_{n_1}^2$ distribution and  $V_2$ is a randome variable with $\chi_{n_2}^2$ distribution, with $V_1$ and $V_2$ independent  
    
    Then $m_{V_1}(t) = (1-2t)^{-n_1/2}$ and $m_{V_2}(t) = (1-2t)^{-n_2/2}$  
    
    By Theorem 6.2, $m_{V_1+V_2}(t) = m_{V_1}(t) \cdot m_{V_2}(t) = (1-2t)^{-n_1/2}(1-2t)^{-n_2/2} = (1-2t)^{-(n_1 + n_2)/2}$  
    
    So $V_1 + V_2$ has a $\chi_{n_1+n_2}^2$ distribution.  
    
    From part b), $\sum\limits_{i = 1}^{5}(Y_i - \overline{Y})^2$ is a $\chi_4^2$ distribution  
    
    By Theorem 7.2, $Y_6^2$ has a $\chi_{1}^2$ distribution.  
    
    Since $\sum\limits_{i = 1}^{5}(Y_i - \overline{Y})^2$ and $Y_6^2$ are independenct, it follows from the arguement just above that $\sum\limits_{i = 1}^{5}(Y_i - \overline{Y})^2 + Y_6^2$ is a $\chi_{5}^2$ distribution.  
    
    --
    
    
    
    
  



    